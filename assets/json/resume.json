{"basics":{"name":"Ayda Sultan","label":"Research Engineer","image":"","email":"se.ayda.sultan@gmail.com"},"work":[{"name":"KAUST","position":"Research Assistant","startDate":"2023-10-19","endDate":"2024-05-09","summary":"Studied methods to create inherently interpretable models by injecting human concepts at various layers of a neural network","highlights":["Concept Bottleneck Models","Linear Algebra","Statistics","Feature Disentanglement"]},{"name":"University of Michigan","position":"Research Assistant","startDate":"2022-05-02","endDate":"2023-05-24","summary":"Studied hand and interacting object segmentation models","highlights":["Image Segmentation","Deep Learning","Semi-supervised Learning"]}],"education":[{"institution":"Addis Ababa Institute of Technology","location":"Addis Ababa, Ethiopia","area":"Software Engineering","studyType":"Bachelor's Degree","startDate":"2018-10-01","endDate":"2023-07-20"}],"publications":[{"name":"Towards a Richer 2D Understanding of Hands at Scale","releaseDate":"2023-09-21","url":"https://proceedings.neurips.cc/paper_files/paper/2023/file/612a7948f3294a02a63d970566ca8536-Paper-Conference.pdf","summary":"As humans, we learn a lot about how to interact with the world by observing others interacting with their hands. To help AI systems obtain a better understanding of hand interactions, we introduce a new model that produces a rich understanding of hand interaction. Our system produces a richer output than past systems at a larger scale. Our outputs include boxes and segments for hands, in-contact objects, and second objects touched by tools as well as contact and grasp type. Supporting this method are annotations of 257K images, 401K hands, 288K objects, and 19K second objects spanning four datasets. We show that our method provides rich information and performs and generalizes well."}],"skills":[{"name":"Python"},{"name":"PyTorch"},{"name":"Matplotlib"},{"name":"NumPy"},{"name":"Flask"},{"name":"Tensorboard"}],"projects":[{"name":"MP2S","summary":"Constantly sitting behind a desk looking at a screen connected to surveillance cameras is an infeasible task for humans. However, this task is quite important for ensuring the safety of public spaces. In most cases, abnormal behavior is left unnoticed which largely compromises the safety of people especially in crowded places. Hence, we propose to build a semi-autonomous system that would alert the person behind the screen when an unusual behavior is detected.","startDate":"2023-01-30","endDate":"2023-07-10","url":"https://drive.google.com/file/d/1djqV3y-xHFYaC-fs3SYLo7vOs9axhBYO/view"}]}